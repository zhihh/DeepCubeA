ä¸‹é¢ç”¨ç›´è§‚çš„çº¿æ€§ä¾‹å­æŠŠæ•´ä¸ªè®­ç»ƒæµç¨‹å’Œå…³é”®å‚æ•°ä¸²èµ·æ¥è§£é‡Šï¼ˆå°½é‡åŒ…å«æ•°å€¼è®¡ç®—ï¼Œä¾¿äºç†è§£ï¼‰ã€‚

**åœºæ™¯åŸºç¡€**ï¼ˆç”¨äºä¸¾ä¾‹ï¼‰
- çŠ¶æ€é“¾ï¼š S0 -> S1 -> S2 -> S3(ç›®æ ‡)ï¼Œæ¯æ­¥ä»£ä»· c=1ï¼ŒçœŸå® cost-to-go h*=[3,2,1,0]ã€‚  
- å‡è®¾åˆå§‹ target network ä¼°è®¡ h_target0=[10,10,10,0]ï¼ˆå³ç›®æ ‡é™¤å¤–ä¼°è®¡å¾ˆå·®ï¼‰ã€‚

**å¸¸è§è¿è¡Œå‚æ•°**ï¼ˆä¸¾ä¾‹ï¼‰
- back_max = 2  
- states_per_update = 20000  
- max_update_steps = 2  
- update_method = GBFS  
- batch_size = 1000  
- epochs_per_update = 1  
- num_update_procs = 1  
- update_nnet_batch_size = 10000  
- lr = 0.001, lr_d = 0.9999993  
- loss_thresh = 0.05  
- single_gpu_training = Falseï¼ˆé»˜è®¤å¯èƒ½åŒ…è£… DataParallelï¼‰  
- max_itrs = 200000

## ğŸ¯ å…³é”®èŠ‚ç‚¹

1) **æ•°æ®ç”Ÿæˆï¼ˆbackwards samplingï¼‰**

- back_max æ§åˆ¶â€œä»ç›®æ ‡å‘åéšæœºèµ°â€çš„æœ€å¤§æ­¥æ•°ã€‚back_max=2 â†’ èµ·ç‚¹å¯èƒ½æ˜¯ S2 æˆ– S1ï¼ˆS0 åªæœ‰åœ¨ back_maxâ‰¥3 æ—¶å‡ºç°ï¼‰ã€‚  
- ä»£ç ä¼šä»ç›®æ ‡åå‘éšæœºé€€æ­¥ç”Ÿæˆå¤§çº¦ states_per_update ä¸ªèµ·ç‚¹ï¼ˆæˆ–åˆ†æ‘Šåˆ°å¤šä»½ï¼Œè§ç¬¬ 3 ç‚¹ï¼‰ã€‚è¿™äº›èµ·ç‚¹æ˜¯è®­ç»ƒçš„â€œåŸå§‹æ ·æœ¬æ¥æºâ€ã€‚

2) **å‘å‰æ‰©å±• / max_update_stepsï¼ˆæŠŠæ›´å¤šçŠ¶æ€åŠ å…¥è®­ç»ƒé›†ï¼‰**

- update_steps = min(update_num+1, max_update_steps)ã€‚è‹¥ update_num åˆå§‹ 0ï¼Œåˆ™ update_steps = 1ï¼Œéšåä¼šå¢åŠ ç›´åˆ° max_update_stepsã€‚  
- max_update_steps=2 æ„å‘³ç€æ¯ä¸ªèµ·ç‚¹ä¼šåšæœ€å¤š 2 æ­¥å‰å‘æœç´¢ï¼ˆç”¨ GBFS/A*ï¼‰ï¼Œæœç´¢è¿‡ç¨‹ä¸­é‡åˆ°çš„ä¸­é—´çŠ¶æ€ä¹ŸåŠ å…¥è®­ç»ƒé›†ã€‚  
- ä¸¾ä¾‹ï¼šèµ·ç‚¹ S1ï¼Œç”¨ 2 æ­¥å‘å‰ä¼šé‡åˆ° S1->S2->S3ï¼ŒæŠŠ S1ã€S2ã€S3 éƒ½æ”¾å…¥è®­ç»ƒé›†ï¼ˆS3 æ˜¯ goalï¼Œctg=0ï¼‰ã€‚

3) **outputs.shape[0] ä¸ states_per_update çš„å…³ç³»**

- å¦‚æœ max_update_steps>1ï¼Œdo_update ä¼šæŠŠ states_per_update åˆ†æˆ update_steps ä»½ï¼Œæ¯ä»½åšå‰å‘æ‰©å±•ï¼Œæœ€ç»ˆ outputs.shape[0]ï¼ˆè®­ç»ƒæ ·æœ¬æ•°ï¼‰é€šå¸¸ä¼šå¤§äºæˆ–â‰ˆstates_per_updateï¼ˆå› ä¸ºæ‰©å±•äº§ç”Ÿé¢å¤–ä¸­é—´çŠ¶æ€ï¼‰ã€‚  
- è¿‘ä¼¼ç®€å•æƒ…å½¢ï¼ˆä¸è€ƒè™‘é‡å¤ï¼‰ï¼šoutputs â‰ˆ states_per_update * average_path_length_from_expansionã€‚

4) **å¤‡ä»½ï¼ˆbackupï¼‰å¦‚ä½•ç”Ÿæˆè®­ç»ƒç›®æ ‡**

- â€œä¸€æ­¥å¤‡ä»½â€å…¬å¼ï¼ˆBellman å¤‡ä»½ï¼‰ï¼š
  target(s) = min_a [ c(s,a) + h_target(s') ]  
- ç”¨ä¾‹ï¼ˆä¸€é˜¶å¤‡ä»½ï¼‰ï¼š
  - å¯¹ S2: target = 1 + h_target(S3) = 1 + 0 = 1  
  - å¯¹ S1: target = 1 + h_target(S2) = 1 + 10 = 11  
  - å¯¹ S0: target = 1 + h_target(S1) = 1 + 10 = 11
- è‹¥å…è®¸ä¸¤æ­¥æ‰©å±•ï¼Œç­‰æ•ˆåšä¸¤æ¬¡ä¸€é˜¶å¤‡ä»½ï¼ˆæˆ–ç›´æ¥ä¸¤æ­¥ bootstrapï¼‰ï¼Œç»“æœä¼šæŠŠä¿¡æ¯ä¼ æ’­ä¸¤å±‚ï¼ˆS1 ä» 11 å˜æˆ 2ï¼ŒS0 å˜æˆ 12ï¼Œè§å‰é¢ç¤ºä¾‹ï¼‰ã€‚

5) **è®­ç»ƒ current networkï¼ˆtrainï¼‰ä¸è®¡æ•° itr**

- outputs.shape[0] = Nï¼ˆæœ¬æ¬¡äº§ç”Ÿçš„è®­ç»ƒæ ·æœ¬æ•°ï¼‰ã€‚  
- num_train_itrs = epochs_per_update * ceil(N / batch_size)ã€‚ ä¾‹ï¼šNâ‰ˆ20000, batch_size=1000 â†’ ceil=20 â†’ num_train_itrs=20ï¼ˆè‹¥ epochs_per_update=1ï¼‰ã€‚  
- itr += num_train_itrsï¼šitr æ˜¯â€œç´¯è®¡çš„æ¢¯åº¦æ›´æ–°æ­¥æ•°â€ï¼Œç”¨äº lr è¡°å‡å’Œ max_itrs ç»ˆæ­¢åˆ¤æ–­ã€‚  
- lr æŒ‰ lr * (lr_d ** itr) è¡°å‡ï¼›ä¸¾ä¾‹ lr0=0.001, lr_dâ‰ˆ0.9999993ï¼š
  - itr=20 â†’ lr â‰ˆ 0.001 * 0.9999993^20 â‰ˆ 0.000999986  
  - è®¸å¤šè½®åï¼ˆitr å¾ˆå¤§ï¼‰lr ä¼šæ˜¾è‘—ä¸‹é™ã€‚

6) **ä»€ä¹ˆæ—¶å€™æŠŠ current å¤åˆ¶åˆ° targetï¼ˆupdateï¼‰**

- æ¯æ¬¡è®­ç»ƒåè®¡ç®— last_lossï¼ˆtrain_nnet è¿”å›ï¼‰ã€‚è‹¥ last_loss < loss_threshï¼ˆä¾‹ 0.05ï¼‰ï¼Œåˆ™æ‰§è¡Œï¼š
  copy_files(curr_dir, targ_dir); update_num += 1  
- è¿™æ · target ç½‘ç»œè¢«â€œæ›´æ–°â€ä¸ºæœ€è¿‘è®­ç»ƒå‡ºçš„ currentï¼›åç»­ do_update ä¼šä»¥æ–°çš„ target æ¥åšå¤‡ä»½ï¼Œä½¿ç›®æ ‡é€æ­¥æ”¹å–„ã€‚

7) **num_update_procs ä¸ update_nnet_batch_size**

- num_update_procs æ§åˆ¶å¹¶è¡Œ worker æ•°é‡ï¼Œè¿™äº› worker è¯»å– targ_dir ä¸‹çš„æ¨¡å‹å¹¶å¹¶è¡Œè¯„ä¼° h_targetï¼ˆåŠ é€Ÿ do_update çš„é¢„æµ‹æ­¥éª¤ï¼‰ã€‚  
- update_nnet_batch_size æ˜¯æ¯ä¸ªè¿›ç¨‹åšæ‰¹é‡é¢„æµ‹æ—¶çš„ batch å¤§å°ï¼Œæ˜¾å­˜ä¸è¶³æ—¶è°ƒå°ã€‚

8) **single_gpu_training ä¸ DataParallel**

- åœ¨ main ä¸­ï¼šè‹¥ on_gpu ä¸” not single_gpu_trainingï¼Œåˆ™ nnet = nn.DataParallel(nnet) â€”â€”è®­ç»ƒæ—¶ä¼šè·¨æ‰€æœ‰ CUDA_VISIBLE_DEVICES å¹¶è¡Œã€‚  
- single_gpu_training ä¼šé¿å… DataParallelï¼Œä»…åœ¨ä¸€ä¸ª GPU ä¸Šè®­ç»ƒï¼ˆä½† update workers ä»å¯ä½¿ç”¨æ‰€æœ‰å¯è§ GPU æ¥è¯„ä¼° targetï¼‰ã€‚

9) **æµ‹è¯•é˜¶æ®µï¼ˆgbfs_testï¼‰**

- æ¯è½®è®­ç»ƒåç”¨å½“å‰ nnet æ„é€  heuristic_fn åšæµ‹è¯•ï¼š max_solve_steps = min(update_num+1, back_max)ï¼ˆå…è®¸çš„æœç´¢æ·±åº¦ç”¨äºæµ‹è¯•ï¼‰ã€‚  
- gbfs_test ç”¨ heuristic_fn åœ¨ num_test ä¸ªæ ·æœ¬ä¸Šè¯„ä¼°è§£ç‡ / å¹³å‡æ­¥æ•°ç­‰ï¼Œç»™è®­ç»ƒè¿‡ç¨‹çš„æ€§èƒ½ä¿¡å·ã€‚

## âš™ï¸ å®Œæ•´æµç¨‹

1. åˆå§‹ï¼šè½½å…¥ currentï¼ˆè‹¥æ— åˆ™éšæœºåˆå§‹ï¼‰ï¼Œtarg_dir å¯èƒ½ä¸ºç©º â†’ all_zeros Trueã€‚  
2. å¯åŠ¨ heur_fn runnerï¼ˆå¤šä¸ªè¿›ç¨‹ï¼‰ç”¨ targ_dir çš„æ¨¡å‹åšå¹¶è¡Œé¢„æµ‹ï¼ˆè‹¥ targ_dir ä¸ºç©ºåˆ™è¿”å›é»˜è®¤ä¼°è®¡ï¼‰ã€‚  
3. do_updateï¼š
   - ä»ç›®æ ‡å‘åéšæœºé€€æ­¥ç”Ÿæˆèµ·ç‚¹ï¼ˆback_max æ§åˆ¶è·ç¦»åˆ†å¸ƒï¼‰ã€‚  
   - å¯¹æ¯ä¸ªèµ·ç‚¹åšæœ€å¤š update_steps çš„å‰å‘æœç´¢ï¼ˆmax_update_steps æ§åˆ¶ä¸Šé™ï¼‰ï¼ŒæŠŠé‡åˆ°çš„çŠ¶æ€æ”¶é›†ä¸ºè®­ç»ƒæ ·æœ¬ã€‚  
   - ç”¨ target network å¯¹åç»§çŠ¶æ€è¯„ä¼° h_target å¹¶åš min-over-actions çš„å¤‡ä»½ï¼Œå¾—åˆ° outputsï¼ˆè®­ç»ƒç›®æ ‡ï¼‰ã€‚  
4. åœæ­¢ heur procsã€‚  
5. train_nnet ç”¨ states_nnet + outputs åœ¨ current ä¸Šåš num_train_itrs æ¬¡æ¢¯åº¦æ›´æ–°ï¼ˆæŒ‰ batch_sizeã€epochs_per_updateï¼‰ã€‚æ›´æ–° itrã€‚  
6. ä¿å­˜ currentï¼ˆstate_dict + itr + update_numï¼‰ã€‚  
7. æµ‹è¯• gbfs_testï¼ˆè¯„ä¼°å½“å‰ heuristicï¼‰ã€‚  
8. è‹¥ last_loss < loss_thresh â†’ copy current â†’ target å¹¶ update_num++ï¼ˆä¸‹è½®å¼€å§‹ update_steps ä¼šå˜å¤§ç›´åˆ° max_update_stepsï¼‰ã€‚  
9. å¦‚æœ itr >= max_itrs åˆ™ç»“æŸï¼Œå¦åˆ™å›åˆ°ç¬¬2æ­¥ã€‚

## ğŸ“ Note:

- å¤‡ä»½ï¼ˆBellman ä¸€æ­¥ï¼‰ç”¨ target çš„ä¼°è®¡è‡ªä¸¾å‡ºè®­ç»ƒç›®æ ‡ï¼›æŠŠ current æ‹Ÿåˆè¿™äº›ç›®æ ‡å¹¶åœ¨ loss è¶³å¤Ÿå°åæŠŠ current å¤åˆ¶ä¸ºæ–°çš„ targetï¼Œå°±åƒâ€œç¨³å®šçš„å€¼è¿­ä»£â€å¾ªåºæ¨è¿›ï¼›å¤šæ¬¡å¾ªç¯åï¼Œä¼°è®¡è¶‹è¿‘çœŸå® ctgï¼ˆåœ¨ç†æƒ³åŒ–æ¡ä»¶ä¸‹ï¼‰ã€‚  
- back_max å†³å®šâ€œä½ è®­ç»ƒå“ªäº›éš¾åº¦çš„èµ·ç‚¹â€ï¼›max_update_steps å†³å®šâ€œåœ¨æ¯ä¸ªèµ·ç‚¹ä¸Šå¾€å‰çœ‹å¤šè¿œä»¥æŠŠä»·å€¼ä¿¡æ¯ä¼ æ’­åˆ°æ›´å¤šçŠ¶æ€â€ã€‚
